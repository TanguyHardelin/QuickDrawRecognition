{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000 images in total\n"
     ]
    }
   ],
   "source": [
    "max_images_per_cathegory = 20000\n",
    "\n",
    "dataset_dir=\"datasets\"\n",
    "dataset_files = os.listdir(dataset_dir)\n",
    "# Count number of drawing\n",
    "count = 0\n",
    "for file in dataset_files:\n",
    "    data  = np.load(os.path.join(dataset_dir,file))\n",
    "    data  = data[:max_images_per_cathegory]\n",
    "    count += data.shape[0]\n",
    "\n",
    "print(count,\"images in total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['axe', 'cloud', 'dragon', 'eye', 'guitar', 'hand', 'piano', 'table', 'television', 'The Eiffel Tower']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images          = np.zeros((count,784))\n",
    "targets         = np.zeros(count)\n",
    "target_names    = []\n",
    "\n",
    "i=0;j=0\n",
    "for file in dataset_files:\n",
    "    d = np.load(os.path.join(dataset_dir,file))\n",
    "    d = d[:max_images_per_cathegory]\n",
    "    images[i:i+d.shape[0]]  = d\n",
    "    targets[i:i+d.shape[0]] = j\n",
    "    i+=d.shape[0]\n",
    "    j+1\n",
    "    target_names.append(file.split(\"full_numpy_bitmap_\")[1].split(\".npy\")[0])\n",
    "\n",
    "print(target_names)\n",
    "plt.imshow(images[0].reshape(28,28))\n",
    "plt.title(\"Test images\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = StandardScaler()\n",
    "images = scalar.fit_transform(images.reshape(-1,28*28))\n",
    "images = images.reshape(-1,28,28,1)\n",
    "images = images.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images,test_images,train_targets,test_targets) = train_test_split(images,targets,test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert data to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images,train_targets))\n",
    "test_dataset  = tf.data.Dataset.from_tensor_slices((test_images,test_targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuickDrawRecognitionModel(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(QuickDrawRecognitionModel, self).__init__()\n",
    "        \n",
    "        #Convolutionnal layes:\n",
    "        self.conv1 = tf.keras.layers.Conv2D(32, 4, activation=\"relu\", name=\"conv1\")\n",
    "        self.conv2 = tf.keras.layers.Conv2D(64, 3, activation=\"relu\", name=\"conv2\")\n",
    "        self.conv3 = tf.keras.layers.Conv2D(128, 3, activation=\"relu\", name=\"conv3\")\n",
    "        \n",
    "        #Flatten layer:\n",
    "        self.flatten_layer = tf.keras.layers.Flatten(name=\"flatten\")\n",
    "        \n",
    "        #Dense & output:\n",
    "        self.d1 = tf.keras.layers.Dense(128,activation=\"relu\",name=\"d1\")\n",
    "        self.out = tf.keras.layers.Dense(10,activation=\"softmax\",name=\"output\")\n",
    "        \n",
    "    def call(self,x):\n",
    "        x = self.conv1(x)\n",
    "        print(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        \n",
    "        x = self.flatten_layer(x)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object     = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "accuracy_object = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "optimizer       = tf.keras.optimizers.Adam()\n",
    "\n",
    "#Accumulateurs:\n",
    "train_loss_history     = tf.keras.metrics.Mean()\n",
    "train_accuracy_history = tf.keras.metrics.Mean()\n",
    "\n",
    "test_loss_history     = tf.keras.metrics.Mean()\n",
    "test_accuracy_history = tf.keras.metrics.Mean()\n",
    "\n",
    "model = QuickDrawRecognitionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images,targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        print(\"Before\")\n",
    "        predictions = model(images)\n",
    "        print(\"After\")\n",
    "        loss = loss_object(targets,predictions)\n",
    "        \n",
    "    gradients = tape.gradient(loss,model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients,model.trainable_variables))\n",
    "    \n",
    "    accuracy = accuracy_object(targets,predictions)\n",
    "    \n",
    "    train_loss_history(loss)\n",
    "    train_accuracy_history(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(images,targets):\n",
    "    predictions = model(images)\n",
    "    loss = loss_object(targets,predictions)\n",
    "    accuracy = accuracy_object(targets,predictions)\n",
    "    \n",
    "    test_loss_history(loss)\n",
    "    test_accuracy_history(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before\n",
      "Tensor(\"quick_draw_recognition_model_1/conv1/Relu:0\", shape=(500, 25, 25, 32), dtype=float32)\n",
      "After\n",
      "Before\n",
      "Tensor(\"quick_draw_recognition_model_1/conv1/Relu:0\", shape=(500, 25, 25, 32), dtype=float32)\n",
      "After\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node quick_draw_recognition_model_1/conv1/Conv2D}}]]\n\t [[GroupCrossDeviceControlEdges_0/Adam/Const/_23]] [Op:__inference_train_step_2956]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-9eeadc451957>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtargets\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtargets\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 438\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_canonicalize_function_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1286\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1288\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m    572\u001b[0m     \"\"\"\n\u001b[0;32m    573\u001b[0m     return self._call_flat(\n\u001b[1;32m--> 574\u001b[1;33m         (t for t in nest.flatten((args, kwargs))\n\u001b[0m\u001b[0;32m    575\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m    576\u001b[0m                            resource_variable_ops.ResourceVariable))))\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    625\u001b[0m     \u001b[1;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 627\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    628\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args)\u001b[0m\n\u001b[0;32m    413\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[0;32m    414\u001b[0m                    \"config_proto\", config),\n\u001b[1;32m--> 415\u001b[1;33m             ctx=ctx)\n\u001b[0m\u001b[0;32m    416\u001b[0m       \u001b[1;31m# Replace empty list with None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_keras_symbolic_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node quick_draw_recognition_model_1/conv1/Conv2D}}]]\n\t [[GroupCrossDeviceControlEdges_0/Adam/Const/_23]] [Op:__inference_train_step_2956]"
     ]
    }
   ],
   "source": [
    "epoch = 100\n",
    "batch_size = 500\n",
    "\n",
    "history={\"train\":{\"accuracy\":[],\"loss\":[]},\"test\":{\"accuracy\":[],\"loss\":[]}}\n",
    "\n",
    "for epoch in range(0,1):\n",
    "    for images,targets in train_dataset.batch(batch_size):\n",
    "        train_step(images,targets)\n",
    "    \n",
    "    for images,targets in test_dataset.batch(batch_size):\n",
    "        test_step(images,targets)\n",
    "    print(\"Epoch\",epoch,\"loss\",train_loss_history.result())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
